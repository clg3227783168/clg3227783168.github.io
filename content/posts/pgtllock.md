---
title: 华为项目介绍
---
总览：解决高并发场景下，因粗粒度读写锁导致的内存性能瓶颈问题

1.在高内存负载的情况下，系统卡顿非常严重。
2.通过perf、火焰图等手段发现内存回收上占用了大量CPU的时间片
3.根本原因是：原有的保护页表操作的锁是粗粒度的读写锁，持有该锁时会锁住一段连续的具有相同读写执行属性的内存页，也就是virtual region。当触发pagefault时，需要建立虚拟页和物理页的映射关系；而想要回收某个物理页，要解除这个物理页和虚拟页的映射关系，都需要持有刚刚说的粗粒度的页表锁。
举个例子，不同CPU操作一个virtual region内的不同页面也会产生竞争。这可能导致可能仅仅是需要回收4KB的内存，就要一直等到整个1MB内存页都处于未被操作的时候才能进行，严重降低内存回收的效率。
因为往往在内存压力大的时候会触发大量内存回收的操作，所以持锁的时间要越短越好。
总结来说，页表锁必须要满足两个条件：
    1锁的粒度要细化，
    2持锁的时间要越短。
所以我采用细粒度自旋锁的方案。并且所有可能发生睡眠或阻塞的操作（比如说页加载，文件类型的页加载可能会触发磁盘IO，需要等待IO返回）禁止在临界区内，确保新锁的临界区非常短，也保证了持锁的时间非常短
由于自旋锁只会忙等待，不会向读写锁一样在写锁争用时会阻塞线程，所以可以避免线程切换的上下文开销

难点：
并发场景下数据一致性的保证
假设我们需要修改某个pte的值
在原有大锁下，保证查询到的pte值可用
但是，由于耗时操作被移出临界区，现在这个pte可能在查询值后，被使用前的这个时间间隙被其他线程修改
所以设计了一个解决方案：在提交最终修改之前，增加一次一致性检查，检查pte的值是否与查询到的值相等

工程适配的难点
由于逻辑比较复杂，涉及到的代码量比较大，所以采用渐进式的页表锁适配策略，先保留旧锁的状态下引入心锁，当一整条路径适配完毕后再将旧锁剥离

由于忙等待会占用CPU，所以在想能不能进一步减少持锁时间，开发了一套基于透明内核对象的快速系统调用接口。
将VMA，也就是描述进程地址空间的信息，包括起始/结束地址，读写执行权限，映射的文件列表等本来属于内核态才能看到的信息以只读的方式映射到用户态，让用户态能够直接看到这些信息，避免陷入内核查询信息的开销